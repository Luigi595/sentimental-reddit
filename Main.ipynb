{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Typical imports for data analysis\n",
    "from IPython import display\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses praw to scrape the headlines from a given subreddit\n",
    "def scraper(sreddit):\n",
    "    hlines=set()\n",
    "    for submission in reddit.subreddit(sreddit).top(limit=None):\n",
    "        hlines.add(submission.title)\n",
    "        display.clear_output()\n",
    "        print(len(hlines))\n",
    "    return hlines\n",
    "\n",
    "#Assigns a sentiment value from -1 to 1 to a list of text\n",
    "def sentimentAnalysis(textList):\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "\n",
    "    for line in textList:\n",
    "        pol_score = sia.polarity_scores(line)\n",
    "        pol_score['headline'] = line\n",
    "        results.append(pol_score)\n",
    "    \n",
    "    return results\n",
    "\n",
    "#Writes a csv file for each subreddit, with each headline and a rounded score (positive, negative, neutral)\n",
    "#This function also writes the positive and negative scores each subreddit got\n",
    "#Should rewrite this.\n",
    "def csvOutput(multiArray,name):\n",
    "    df=pd.DataFrame.from_records(multiArray)\n",
    "    df['label'] = 0\n",
    "    df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "    df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "    \n",
    "    df2 = df[['headline', 'label']]\n",
    "    df2.to_csv('headlines_'+ name +'.csv', mode='a', encoding='utf-8', index=False)\n",
    "    \n",
    "    print(df.label.value_counts())\n",
    "\n",
    "    print(df.label.value_counts(normalize=True) * 100)\n",
    "    \n",
    "    test=(df.label.value_counts(normalize=True) * 100).tolist()\n",
    "    poslist.append(test[1])\n",
    "    neglist.append(test[2])\n",
    "    \n",
    "    tokenCount(df)\n",
    "    \n",
    "#Tokenizes the words in each headline, barring stop words\n",
    "def processText(headlines):\n",
    "    tokens = []\n",
    "    for line in headlines:\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t.lower() for t in toks if t.lower() not in stop_words]\n",
    "        tokens.extend(toks)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "#Finds the words most commonly used in positive and negative headlines\n",
    "def tokenCount(df):\n",
    "    pos_lines = list(df[df.label == 1].headline)\n",
    "\n",
    "    pos_tokens = processText(pos_lines)\n",
    "    pos_freq = nltk.FreqDist(pos_tokens)\n",
    "\n",
    "    pwordslist.append(pos_freq.most_common(3))\n",
    "    \n",
    "    neg_lines = list(df[df.label == -1].headline)\n",
    "\n",
    "    neg_tokens = processText(neg_lines)\n",
    "    neg_freq = nltk.FreqDist(neg_tokens)\n",
    "\n",
    "    nwordslist.append(neg_freq.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      " 0    450\n",
      " 1    342\n",
      "-1    203\n",
      "Name: label, dtype: int64\n",
      " 0    45.226131\n",
      " 1    34.371859\n",
      "-1    20.402010\n",
      "Name: label, dtype: float64\n",
      "this is test\n",
      "[45.22613065326633, 34.37185929648241, 20.402010050251256]\n",
      "[35.07537688442211, 34.37185929648241]\n",
      "[35.07537688442211, 34.37185929648241]\n",
      "[21.20603015075377, 20.402010050251256]\n",
      "[[('nfl', 62), ('game', 58), ('like', 38)], [('nba', 61), ('lebron', 59), ('game', 44)]]\n",
      "[[('nfl', 35), ('game', 23), ('team', 16)], [('game', 30), ('lebron', 22), ('nba', 20)]]\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "#In order to use this code, replace the placeholders with the data given by reddit\n",
    "reddit = praw.Reddit(client_id='your-client-id',\n",
    "                     client_secret='your-client-secret',\n",
    "                     user_agent='your-reddit-username')\n",
    "\n",
    "#Some test subs, including teams from the EPL, NFL, NBA\n",
    "subs=['nfl','nba']\n",
    "#subs=['AFCBournemouth', 'Gunners', 'BrightonHoveAlbion', 'burnley', 'bluebirds', 'chelseafc', 'crystalpalace', 'Everton', 'fulhamfc', 'HuddersfieldTownFC', 'lcfc', 'LiverpoolFC', 'MCFC', 'reddevils', 'NUFC', 'SaintsFC', 'coys', 'Watford_FC', 'WWFC', 'Hammers']\n",
    "#subs=[\"ravens\",\"steelers\",\"browns\",\"bengals\",\"patriots\",\"miamidolphins\",\"buffalobills\",\"nyjets\",\"chibears\",\"minnesotavikings\",\"greenbaypackers\",\"detroitlions\",\"cowboys\",\"eagles\",\"redskins\",\"nygiants\",\"texans\",\"colts\",\"tennesseetitans\",\"jaguars\",\"kansascitychiefs\",\"chargers\",\"denverbroncos\",\"oaklandraiders\",\"saints\",\"falcons\",\"panthers\",\"buccaneers\",\"losangelesrams\",\"seahawks\",\"49ers\",\"azcardinals\"]\n",
    "#subs=[\"mavericks\",\"denvernuggets\",\"warriors\",\"rockets\",\"laclippers\",\"lakers\",\"memphisgrizzlies\",\"timberwolves\",\"nolapelicans\",\"thunder\",\"suns\",\"ripcity\",\"kings\",\"nbaspurs\",\"utahjazz\",\"nba\",\"atlantahawks\",\"bostonceltics\",\"gonets\",\"charlottehornets\",\"chicagobulls\",\"clevelandcavs\",\"detroitpistons\",\"pacers\",\"heat\",\"mkebucks\",\"nyknicks\",\"orlandomagic\",\"sixers\",\"torontoraptors\",\"washingtonwizards\"]\n",
    "poslist=[]\n",
    "neglist=[]\n",
    "pwordslist=[]\n",
    "nwordslist=[]\n",
    "\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "for club in subs:\n",
    "    headlines = scraper(club)\n",
    "    sentiments = sentimentAnalysis(headlines)\n",
    "    csvOutput(sentiments,club)\n",
    "    \n",
    "    \n",
    "print(poslist)\n",
    "print(neglist)\n",
    "print(pwordslist)\n",
    "print(nwordslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathers the outputs and presents it as a dataframe\n",
    "test=[]\n",
    "for i in range(len(subs)):\n",
    "    test.append([subs[i],poslist[i],neglist[i],poslist[i]-neglist[i],pwordslist[i],nwordslist[i]])\n",
    "outputdf=pd.DataFrame(test, columns=['Sub','Positive %', \"Negative %\",\"Difference\",\"Positive Words\", \"Negative Words\"], index=range(1,len(subs)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub</th>\n",
       "      <th>Positive %</th>\n",
       "      <th>Negative %</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Negative Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nba</td>\n",
       "      <td>34.371859</td>\n",
       "      <td>20.40201</td>\n",
       "      <td>13.969849</td>\n",
       "      <td>[(nba, 61), (lebron, 59), (game, 44)]</td>\n",
       "      <td>[(game, 30), (lebron, 22), (nba, 20)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfl</td>\n",
       "      <td>35.075377</td>\n",
       "      <td>21.20603</td>\n",
       "      <td>13.869347</td>\n",
       "      <td>[(nfl, 62), (game, 58), (like, 38)]</td>\n",
       "      <td>[(nfl, 35), (game, 23), (team, 16)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sub  Positive %  Negative %  Difference  \\\n",
       "0  nba   34.371859    20.40201   13.969849   \n",
       "1  nfl   35.075377    21.20603   13.869347   \n",
       "\n",
       "                          Positive Words  \\\n",
       "0  [(nba, 61), (lebron, 59), (game, 44)]   \n",
       "1    [(nfl, 62), (game, 58), (like, 38)]   \n",
       "\n",
       "                          Negative Words  \n",
       "0  [(game, 30), (lebron, 22), (nba, 20)]  \n",
       "1    [(nfl, 35), (game, 23), (team, 16)]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pholder=outputdf.sort_values(by=\"Difference\", ascending=False)\n",
    "pholder.reset_index(drop=True, inplace=True)\n",
    "pholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
